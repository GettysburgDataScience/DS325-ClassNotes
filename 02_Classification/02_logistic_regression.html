
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2. Logistic Regression &#8212; DS325 Applied Data Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=720ed60b" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=fb9458d3" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=720ed60b" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/theme.css?v=a243ae73" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '02_Classification/02_logistic_regression';</script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/searchtools.js?v=63a53a7d"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../_static/language_data.js?v=d4673a71"></script>
    <script src="../_static/copybutton_funcs.js?v=776a791e"></script>
    <script src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/scripts/bootstrap.js?v=7583a70d"></script>
    <script src="../_static/scripts/fontawesome.js?v=9b125980"></script>
    <script src="../_static/scripts/pydata-sphinx-theme.js?v=a1eb5d9f"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. Trees and Ensemble methods" href="03_trees_encoding.html" />
    <link rel="prev" title="1. Classification" href="01_classification_intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/ds325_sticker.png" class="logo__image only-light" alt="DS325 Applied Data Science - Home"/>
    <img src="../_static/ds325_sticker.png" class="logo__image only-dark pst-js-only" alt="DS325 Applied Data Science - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to DS325 Applied Data Science
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Setting Up and Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00_Resources/setup.html">1. Setting Up</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Resources/genai_policy.html">2. Our course GenAI Policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_LinearRegression/00_reviewtopics.html">3. Linear Regression Review Topics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Regression</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01_LinearRegression/00_what_is_a_model.html">1. What is a model?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_LinearRegression/01_linear_regression.html">2. Linear Regression (Part 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_LinearRegression/02_linear_regression.html">3. Linear Regression (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_LinearRegression/03_regularization.html">4. Bias, Variance, and Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_LinearRegression/03_regularization_housing.html">5. Regularization Example: King County housing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_LinearRegression/04_polynomial_regression.html">6. Polynomial Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Classification</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_classification_intro.html">1. Classification</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">2. Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_trees_encoding.html">3. Trees and Ensemble methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_trees_gridcv.html">4. Tree Methods (continued)</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00_Assignments/submitting.html">Github Submission Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Assignments/ps00.html">PS00</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Assignments/ps00_Roth.html">PS00 (Solutions by Prof Roth)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Assignments/ps01.html">PS01 - (Not so) Simple Linear Regression</a></li>

<li class="toctree-l1"><a class="reference internal" href="../00_Assignments/ps02.html">PS02 - Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Assignments/mp01.html">Mini-Project 1 (and examples!)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_Assignments/ps03.html">PS03 - Classification</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F02_Classification/02_logistic_regression.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/02_Classification/02_logistic_regression.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Logistic Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-simple-logistic-regression-as-a-classifier">2.1. Example: Simple Logistic Regression as a Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-logistic-function">2.2. The Logistic Function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-and-linear-regression">2.3. Logistic and Linear Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-function">2.3.1. Cost Function</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#back-to-the-example">2.4. Back to the Example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assessing-the-model">2.4.1. Assessing the model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-in-logistic-regression">2.5. Regularization in Logistic Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#improving-our-model">2.5.1. Improving our model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">2.5.2. Assessing the model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#another-example-classifying-wines">2.6. Another Example: Classifying Wines</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="logistic-regression">
<h1><span class="section-number">2. </span>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Link to this heading">#</a></h1>
<p>Is it regression or classification? Yes.</p>
<p>Let’s start differently, with an example.</p>
<section id="example-simple-logistic-regression-as-a-classifier">
<h2><span class="section-number">2.1. </span>Example: Simple Logistic Regression as a Classifier<a class="headerlink" href="#example-simple-logistic-regression-as-a-classifier" title="Link to this heading">#</a></h2>
<p>Let’s revisit the breast cancer dataset. The data comprise numerous physical features of a tumor (e.g. area, texture, symmetry, etc.) and each feature set is labeled with a binary target, benign or malignant.</p>
<p><strong>Note</strong>: In the original data set, benign tumors are labeled 1 and malignant tumors 0. This seems backwards to me and every time I look at these data, my wrong intuition beats out my terrible memory. So, in the example below, I’ve swapped the labeling so that 1 and 0 correspond to malignant and benign, respectively. So:</p>
<ul class="simple">
<li><p>0 = benign</p></li>
<li><p>1 = malignant</p></li>
</ul>
<p>We’ll first fit a simple logistic regression, predicting malignancy based on just one feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_breast_cancer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the breast cancer dataset</span>
<span class="n">bc_df</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Adding the target to the DataFrame of features</span>
<span class="c1"># AND FLIPPING THE LABELS OF THE TARGET</span>
<span class="c1"># 1 - malignant</span>
<span class="c1"># 0 - benign</span>
<span class="n">bc_df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">y</span>

<span class="n">display</span><span class="p">(</span><span class="n">bc_df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">bc_df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean radius</th>
      <th>mean texture</th>
      <th>mean perimeter</th>
      <th>mean area</th>
      <th>mean smoothness</th>
      <th>mean compactness</th>
      <th>mean concavity</th>
      <th>mean concave points</th>
      <th>mean symmetry</th>
      <th>mean fractal dimension</th>
      <th>...</th>
      <th>worst texture</th>
      <th>worst perimeter</th>
      <th>worst area</th>
      <th>worst smoothness</th>
      <th>worst compactness</th>
      <th>worst concavity</th>
      <th>worst concave points</th>
      <th>worst symmetry</th>
      <th>worst fractal dimension</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>...</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
      <td>569.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>14.127292</td>
      <td>19.289649</td>
      <td>91.969033</td>
      <td>654.889104</td>
      <td>0.096360</td>
      <td>0.104341</td>
      <td>0.088799</td>
      <td>0.048919</td>
      <td>0.181162</td>
      <td>0.062798</td>
      <td>...</td>
      <td>25.677223</td>
      <td>107.261213</td>
      <td>880.583128</td>
      <td>0.132369</td>
      <td>0.254265</td>
      <td>0.272188</td>
      <td>0.114606</td>
      <td>0.290076</td>
      <td>0.083946</td>
      <td>0.372583</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.524049</td>
      <td>4.301036</td>
      <td>24.298981</td>
      <td>351.914129</td>
      <td>0.014064</td>
      <td>0.052813</td>
      <td>0.079720</td>
      <td>0.038803</td>
      <td>0.027414</td>
      <td>0.007060</td>
      <td>...</td>
      <td>6.146258</td>
      <td>33.602542</td>
      <td>569.356993</td>
      <td>0.022832</td>
      <td>0.157336</td>
      <td>0.208624</td>
      <td>0.065732</td>
      <td>0.061867</td>
      <td>0.018061</td>
      <td>0.483918</td>
    </tr>
    <tr>
      <th>min</th>
      <td>6.981000</td>
      <td>9.710000</td>
      <td>43.790000</td>
      <td>143.500000</td>
      <td>0.052630</td>
      <td>0.019380</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.106000</td>
      <td>0.049960</td>
      <td>...</td>
      <td>12.020000</td>
      <td>50.410000</td>
      <td>185.200000</td>
      <td>0.071170</td>
      <td>0.027290</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.156500</td>
      <td>0.055040</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>11.700000</td>
      <td>16.170000</td>
      <td>75.170000</td>
      <td>420.300000</td>
      <td>0.086370</td>
      <td>0.064920</td>
      <td>0.029560</td>
      <td>0.020310</td>
      <td>0.161900</td>
      <td>0.057700</td>
      <td>...</td>
      <td>21.080000</td>
      <td>84.110000</td>
      <td>515.300000</td>
      <td>0.116600</td>
      <td>0.147200</td>
      <td>0.114500</td>
      <td>0.064930</td>
      <td>0.250400</td>
      <td>0.071460</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>13.370000</td>
      <td>18.840000</td>
      <td>86.240000</td>
      <td>551.100000</td>
      <td>0.095870</td>
      <td>0.092630</td>
      <td>0.061540</td>
      <td>0.033500</td>
      <td>0.179200</td>
      <td>0.061540</td>
      <td>...</td>
      <td>25.410000</td>
      <td>97.660000</td>
      <td>686.500000</td>
      <td>0.131300</td>
      <td>0.211900</td>
      <td>0.226700</td>
      <td>0.099930</td>
      <td>0.282200</td>
      <td>0.080040</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>15.780000</td>
      <td>21.800000</td>
      <td>104.100000</td>
      <td>782.700000</td>
      <td>0.105300</td>
      <td>0.130400</td>
      <td>0.130700</td>
      <td>0.074000</td>
      <td>0.195700</td>
      <td>0.066120</td>
      <td>...</td>
      <td>29.720000</td>
      <td>125.400000</td>
      <td>1084.000000</td>
      <td>0.146000</td>
      <td>0.339100</td>
      <td>0.382900</td>
      <td>0.161400</td>
      <td>0.317900</td>
      <td>0.092080</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>28.110000</td>
      <td>39.280000</td>
      <td>188.500000</td>
      <td>2501.000000</td>
      <td>0.163400</td>
      <td>0.345400</td>
      <td>0.426800</td>
      <td>0.201200</td>
      <td>0.304000</td>
      <td>0.097440</td>
      <td>...</td>
      <td>49.540000</td>
      <td>251.200000</td>
      <td>4254.000000</td>
      <td>0.222600</td>
      <td>1.058000</td>
      <td>1.252000</td>
      <td>0.291000</td>
      <td>0.663800</td>
      <td>0.207500</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 31 columns</p>
</div></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>count    569.000000
mean       0.372583
std        0.483918
min        0.000000
25%        0.000000
50%        0.000000
75%        1.000000
max        1.000000
Name: y, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># sns.pairplot(bc_df)</span>
<span class="c1"># plt.show()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bc_corr</span> <span class="o">=</span> <span class="n">bc_df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">bc_corr</span><span class="p">,</span> <span class="n">annot</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span> <span class="o">=</span> <span class="s1">&#39;.2f&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d15aa926a714ae90c89f145a54cf44dc428a38432911621af9606fd0d1233c6e.png" src="../_images/d15aa926a714ae90c89f145a54cf44dc428a38432911621af9606fd0d1233c6e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bc_corr</span> <span class="o">=</span> <span class="n">bc_df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">bc_corr</span><span class="p">[[</span><span class="s1">&#39;y&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>y</th>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>worst concave points</th>
      <td>0.793566</td>
    </tr>
    <tr>
      <th>worst perimeter</th>
      <td>0.782914</td>
    </tr>
    <tr>
      <th>mean concave points</th>
      <td>0.776614</td>
    </tr>
    <tr>
      <th>worst radius</th>
      <td>0.776454</td>
    </tr>
    <tr>
      <th>mean perimeter</th>
      <td>0.742636</td>
    </tr>
    <tr>
      <th>worst area</th>
      <td>0.733825</td>
    </tr>
    <tr>
      <th>mean radius</th>
      <td>0.730029</td>
    </tr>
    <tr>
      <th>mean area</th>
      <td>0.708984</td>
    </tr>
    <tr>
      <th>mean concavity</th>
      <td>0.696360</td>
    </tr>
    <tr>
      <th>worst concavity</th>
      <td>0.659610</td>
    </tr>
    <tr>
      <th>mean compactness</th>
      <td>0.596534</td>
    </tr>
    <tr>
      <th>worst compactness</th>
      <td>0.590998</td>
    </tr>
    <tr>
      <th>radius error</th>
      <td>0.567134</td>
    </tr>
    <tr>
      <th>perimeter error</th>
      <td>0.556141</td>
    </tr>
    <tr>
      <th>area error</th>
      <td>0.548236</td>
    </tr>
    <tr>
      <th>worst texture</th>
      <td>0.456903</td>
    </tr>
    <tr>
      <th>worst smoothness</th>
      <td>0.421465</td>
    </tr>
    <tr>
      <th>worst symmetry</th>
      <td>0.416294</td>
    </tr>
    <tr>
      <th>mean texture</th>
      <td>0.415185</td>
    </tr>
    <tr>
      <th>concave points error</th>
      <td>0.408042</td>
    </tr>
    <tr>
      <th>mean smoothness</th>
      <td>0.358560</td>
    </tr>
    <tr>
      <th>mean symmetry</th>
      <td>0.330499</td>
    </tr>
    <tr>
      <th>worst fractal dimension</th>
      <td>0.323872</td>
    </tr>
    <tr>
      <th>compactness error</th>
      <td>0.292999</td>
    </tr>
    <tr>
      <th>concavity error</th>
      <td>0.253730</td>
    </tr>
    <tr>
      <th>fractal dimension error</th>
      <td>0.077972</td>
    </tr>
    <tr>
      <th>symmetry error</th>
      <td>-0.006522</td>
    </tr>
    <tr>
      <th>texture error</th>
      <td>-0.008303</td>
    </tr>
    <tr>
      <th>mean fractal dimension</th>
      <td>-0.012838</td>
    </tr>
    <tr>
      <th>smoothness error</th>
      <td>-0.067016</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature</span> <span class="o">=</span> <span class="s1">&#39;worst concave points&#39;</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">bc_df</span><span class="p">[[</span><span class="n">feature</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">bc_df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConfusionMatrixDisplay</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split the dataset into training and testing sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">59</span><span class="p">)</span>

<span class="c1"># Train a logistic regression model</span>
<span class="n">model_LogReg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">model_LogReg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Make predictions</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model_LogReg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TP</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span>
<span class="n">TN</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>
<span class="n">FP</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>
<span class="n">FN</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span>

<span class="n">right</span> <span class="o">=</span> <span class="s1">&#39;forestgreen&#39;</span>
<span class="n">wrong</span> <span class="o">=</span> <span class="s1">&#39;firebrick&#39;</span>
<span class="n">positive</span> <span class="o">=</span> <span class="s1">&#39;+&#39;</span>
<span class="n">negative</span> <span class="o">=</span> <span class="s1">&#39;s&#39;</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">TP</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">TP</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">right</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">positive</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;True Positive&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">TN</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">TN</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">right</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">negative</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;True Negative&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">FP</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">FP</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">wrong</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">positive</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;False Positive&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">FN</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">FN</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">wrong</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">negative</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;False Negative&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d6c3e7c84a9ef183b0ed8ca3e84d2f931104eaadc645acf14986fa96b1ed3688.png" src="../_images/d6c3e7c84a9ef183b0ed8ca3e84d2f931104eaadc645acf14986fa96b1ed3688.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred_prob</span> <span class="o">=</span> <span class="n">model_LogReg</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred_prob</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[5.44077032e-01, 4.55922968e-01],
       [9.62062910e-01, 3.79370899e-02],
       [9.57331930e-01, 4.26680697e-02],
       [9.99721296e-01, 2.78704480e-04],
       [1.46279385e-01, 8.53720615e-01],
       [2.08250039e-01, 7.91749961e-01],
       [9.99721296e-01, 2.78704480e-04],
       [8.87634417e-01, 1.12365583e-01],
       [9.05480794e-01, 9.45192059e-02],
       [8.75698342e-01, 1.24301658e-01],
       [1.25467803e-01, 8.74532197e-01],
       [1.18044894e-02, 9.88195511e-01],
       [2.51504627e-01, 7.48495373e-01],
       [6.74321801e-01, 3.25678199e-01],
       [5.83207275e-01, 4.16792725e-01],
       [9.13925978e-02, 9.08607402e-01],
       [9.84872909e-01, 1.51270914e-02],
       [9.90642327e-01, 9.35767331e-03],
       [9.62771546e-01, 3.72284541e-02],
       [5.37995787e-01, 4.62004213e-01],
       [9.93737280e-01, 6.26271980e-03],
       [9.56828937e-01, 4.31710631e-02],
       [4.19100013e-02, 9.58089999e-01],
       [2.81397609e-01, 7.18602391e-01],
       [1.19545310e-01, 8.80454690e-01],
       [6.51251169e-02, 9.34874883e-01],
       [9.95730447e-01, 4.26955263e-03],
       [2.82637326e-01, 7.17362674e-01],
       [9.98423814e-01, 1.57618596e-03],
       [1.67298032e-01, 8.32701968e-01],
       [9.92748756e-01, 7.25124437e-03],
       [8.21984874e-01, 1.78015126e-01],
       [8.45805817e-03, 9.91541942e-01],
       [2.57311209e-01, 7.42688791e-01],
       [1.44000467e-01, 8.55999533e-01],
       [9.45816607e-01, 5.41833934e-02],
       [4.93604510e-02, 9.50639549e-01],
       [9.94545476e-01, 5.45452389e-03],
       [9.84624642e-01, 1.53753577e-02],
       [7.49056048e-03, 9.92509440e-01],
       [2.68934852e-02, 9.73106515e-01],
       [7.21985647e-01, 2.78014353e-01],
       [9.99721296e-01, 2.78704480e-04],
       [4.21565347e-02, 9.57843465e-01],
       [8.53803448e-05, 9.99914620e-01],
       [4.57519380e-03, 9.95424806e-01],
       [4.80376467e-03, 9.95196235e-01],
       [9.48482438e-01, 5.15175616e-02],
       [9.90081448e-01, 9.91855209e-03],
       [2.03050833e-02, 9.79694917e-01],
       [2.22736444e-01, 7.77263556e-01],
       [9.28301925e-01, 7.16980749e-02],
       [9.68693845e-01, 3.13061549e-02],
       [1.73688304e-02, 9.82631170e-01],
       [9.40399971e-04, 9.99059600e-01],
       [9.93891585e-01, 6.10841495e-03],
       [9.96122594e-01, 3.87740572e-03],
       [9.74880458e-01, 2.51195423e-02],
       [9.98907860e-01, 1.09213978e-03],
       [3.90571874e-02, 9.60942813e-01],
       [1.26930061e-02, 9.87306994e-01],
       [9.57952801e-01, 4.20471993e-02],
       [3.37541527e-01, 6.62458473e-01],
       [2.63204709e-01, 7.36795291e-01],
       [2.54884107e-02, 9.74511589e-01],
       [6.04436804e-02, 9.39556320e-01],
       [9.88205705e-01, 1.17942949e-02],
       [4.93604510e-02, 9.50639549e-01],
       [3.14502725e-04, 9.99685497e-01],
       [9.97886484e-01, 2.11351555e-03],
       [3.97524251e-02, 9.60247575e-01],
       [9.64592586e-01, 3.54074144e-02],
       [9.87007610e-01, 1.29923902e-02],
       [9.99721296e-01, 2.78704480e-04],
       [1.22328155e-03, 9.98776718e-01],
       [9.97204301e-01, 2.79569920e-03],
       [4.73877860e-02, 9.52612214e-01],
       [8.55048130e-01, 1.44951870e-01],
       [2.29160968e-01, 7.70839032e-01],
       [9.41556212e-01, 5.84437883e-02],
       [6.84922452e-05, 9.99931508e-01],
       [9.88205705e-01, 1.17942949e-02],
       [8.32482479e-01, 1.67517521e-01],
       [6.32859195e-02, 9.36714080e-01],
       [9.52374732e-01, 4.76252677e-02],
       [6.70139405e-02, 9.32986060e-01],
       [9.99721296e-01, 2.78704480e-04],
       [8.95446175e-01, 1.04553825e-01],
       [9.23081659e-01, 7.69183412e-02],
       [9.91747022e-01, 8.25297820e-03],
       [9.82019225e-01, 1.79807747e-02],
       [1.60613162e-02, 9.83938684e-01],
       [4.36650887e-02, 9.56334911e-01],
       [9.55986599e-01, 4.40134013e-02],
       [9.36329283e-01, 6.36707175e-02],
       [9.25015210e-01, 7.49847904e-02],
       [9.44579811e-01, 5.54201895e-02],
       [2.06934066e-03, 9.97930659e-01],
       [9.94034854e-01, 5.96514559e-03],
       [9.87007610e-01, 1.29923902e-02],
       [9.81910797e-01, 1.80892033e-02],
       [4.29859288e-01, 5.70140712e-01],
       [8.98053722e-01, 1.01946278e-01],
       [8.73685169e-01, 1.26314831e-01],
       [1.60087715e-03, 9.98399123e-01],
       [9.89012068e-01, 1.09879322e-02],
       [9.87575970e-01, 1.24240303e-02],
       [9.99241979e-01, 7.58021348e-04],
       [9.95845992e-01, 4.15400758e-03],
       [9.79845732e-01, 2.01542680e-02],
       [6.20354615e-04, 9.99379645e-01],
       [3.94277545e-01, 6.05722455e-01],
       [4.66180777e-01, 5.33819223e-01],
       [9.91605518e-01, 8.39448225e-03]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">TP</span><span class="p">],</span> <span class="n">y_pred_prob</span><span class="p">[</span><span class="n">TP</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">right</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">positive</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;True Positive&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">TN</span><span class="p">],</span> <span class="n">y_pred_prob</span><span class="p">[</span><span class="n">TN</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">right</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">negative</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;True Negative&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">FP</span><span class="p">],</span> <span class="n">y_pred_prob</span><span class="p">[</span><span class="n">FP</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">wrong</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">positive</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;False Positive&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">FN</span><span class="p">],</span> <span class="n">y_pred_prob</span><span class="p">[</span><span class="n">FN</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">wrong</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">negative</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;False Negative&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted Malignancy (Prob %)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/db537de884e922fdcc50f13ddbb052da546b696bfdffaa39ba917c5a594d2a74.png" src="../_images/db537de884e922fdcc50f13ddbb052da546b696bfdffaa39ba917c5a594d2a74.png" />
</div>
</div>
<p>What is this shape?</p>
</section>
<section id="the-logistic-function">
<h2><span class="section-number">2.2. </span>The Logistic Function<a class="headerlink" href="#the-logistic-function" title="Link to this heading">#</a></h2>
<p>The logistic function is a smooth monotonically increasing (means goes up as x goes up) curve with a range of (0, 1). It trends to 0 as x decreases and trends to 1 as x increases with a value of 0.5 at x=0.</p>
<p>This is the logistic function:</p>
<div class="math notranslate nohighlight">
\[
\sigma(t) = \frac{1}{1+\exp(-t)}
\]</div>
<p>Let’s take a look at this function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">logistic</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">t</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Exponential function exp(t)&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">logistic</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Logistic function&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;t&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Prob&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/34c3303b4c268b17fe81fa03e161ff8a646a4f290f816735f1216fe244508903.png" src="../_images/34c3303b4c268b17fe81fa03e161ff8a646a4f290f816735f1216fe244508903.png" />
</div>
</div>
<p>For the plots above:</p>
<ul class="simple">
<li><p>as t gets to be a big positive number, <span class="math notranslate nohighlight">\(\exp(-t)\)</span> goes to 0 and <span class="math notranslate nohighlight">\(\sigma(t)\)</span> goes to 1.</p></li>
<li><p>as t gets to be a big negative number, <span class="math notranslate nohighlight">\(\exp(-t)\)</span> goes to <span class="math notranslate nohighlight">\(+\infty\)</span> and <span class="math notranslate nohighlight">\(\sigma(t)\)</span> goes to 0.</p></li>
</ul>
<p>The logistic function actually furnishes a probability. When we use logistic regression for classification, we set a decision threshold for the probability, 50% by default.</p>
<p>We denote the predicted probability as <span class="math notranslate nohighlight">\(\hat{p}\)</span>.</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(\hat{p}=\sigma(t)&gt;0.5\)</span> then 1 is more likely than 0, so classify as 1</p></li>
<li><p>If <span class="math notranslate nohighlight">\(\hat{p}=\sigma(t)&lt;0.5\)</span> then 0 is more likely than 1, so classify as 0</p></li>
</ul>
<p>50% is a default threshold. It’s a good decision value if either case has equal consequence.</p>
<ul class="simple">
<li><p>Improving Precision: We can raise the threshold if we want to be more discerning about what we classify as 1.</p></li>
<li><p>Improving Recall: Conversely, we can lower the threshold if we want to catch more instances of 1.</p></li>
</ul>
</section>
<section id="logistic-and-linear-regression">
<h2><span class="section-number">2.3. </span>Logistic and Linear Regression<a class="headerlink" href="#logistic-and-linear-regression" title="Link to this heading">#</a></h2>
<p>Why are these two topics in the same chapter?</p>
<p>Let’s look back at the logistic function?</p>
<div class="math notranslate nohighlight">
\[
\sigma(t) = \frac{1}{1+\exp(-t)}
\]</div>
<p>What are the parameters of this model? I don’t see any. That’s because they’re hidden inside <span class="math notranslate nohighlight">\(t\)</span>.</p>
<div class="math notranslate nohighlight">
\[
t = \theta_0 + \theta_1 \cdot x_1 + \cdots + \theta_n \cdot x_n
\]</div>
<p>The value of <span class="math notranslate nohighlight">\(t\)</span> is the output of a linear model (and it can be any flavor of regularized linear model too!). So the parameters of a logistic regression are actually the coefficients of a linear regression (or Lasso or Ridge or ElasticNet). What does this linear model do?</p>
<p>The linear equation maps feature vectors to the range <span class="math notranslate nohighlight">\((-\infty, +\infty)\)</span>. Features that should be classified as 1 get assigned positive numbers, larger for more certain classifications; features that should be classified as 0 get assigned negative numbers, larger negative for more certain classifications.</p>
<section id="cost-function">
<h3><span class="section-number">2.3.1. </span>Cost Function<a class="headerlink" href="#cost-function" title="Link to this heading">#</a></h3>
<p>The <em>loss function</em> minimized for any prediction is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
c(\Theta) = 
\begin{cases}
    -\log(\hat{p}) &amp; \text{if $y=1$}.\\
    -\log(1-\hat{p}) &amp; \text{if $y=0$}.
\end{cases}
\end{split}\]</div>
<p>The <em>cost function</em> minimized for logistic regression is the <em>log-loss</em> function.</p>
<div class="math notranslate nohighlight">
\[
J_{\text{LogLoss}}(\Theta) = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(\hat{p}_i) + (1 - y_i) \log(1 - \hat{p}_i) \right]
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(-0.6931471805599453)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Log function&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Log(Prob)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c546f6894034d6574ef61a0edb8fdc56ffac61ca2f5b6f7f997789d3cf6bcd3d.png" src="../_images/c546f6894034d6574ef61a0edb8fdc56ffac61ca2f5b6f7f997789d3cf6bcd3d.png" />
</div>
</div>
</section>
</section>
<section id="back-to-the-example">
<h2><span class="section-number">2.4. </span>Back to the Example<a class="headerlink" href="#back-to-the-example" title="Link to this heading">#</a></h2>
<p>Now, let’s use all of our features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">bc_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">bc_df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>


<span class="c1"># Split the dataset into training and testing sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Scale the data, since we are using multiple features</span>
<span class="n">ss</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Train a logistic regression model</span>
<span class="n">model_LogReg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">model_LogReg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Make predictions</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">model_LogReg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model_LogReg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">y_pred_prob</span> <span class="o">=</span> <span class="n">model_LogReg</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TP</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span>
<span class="n">TN</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>
<span class="n">FP</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>
<span class="n">FN</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_test</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">TP</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">TP</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">right</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">positive</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;True Positive&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">TN</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">TN</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">right</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">negative</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;True Negative&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">FP</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">FP</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">wrong</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">positive</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;False Positive&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">FN</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">FN</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">wrong</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="n">negative</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;False Negative&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/db2b7853ba19b1e16e00e1b90e0af2b7e9cc6238558ecca20e605638a03d3900.png" src="../_images/db2b7853ba19b1e16e00e1b90e0af2b7e9cc6238558ecca20e605638a03d3900.png" />
</div>
</div>
<section id="assessing-the-model">
<h3><span class="section-number">2.4.1. </span>Assessing the model<a class="headerlink" href="#assessing-the-model" title="Link to this heading">#</a></h3>
<p>How’d we do?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">,</span> 
                                        <span class="c1"># normalize = &#39;true&#39;,</span>
                                        <span class="n">display_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Benign&#39;</span><span class="p">,</span> <span class="s1">&#39;Malignant&#39;</span><span class="p">],</span>
                                        <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;GnBu&#39;</span><span class="p">,</span>
                                        <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> 
                                        <span class="c1"># normalize = &#39;true&#39;,</span>
                                        <span class="n">display_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Benign&#39;</span><span class="p">,</span> <span class="s1">&#39;Malignant&#39;</span><span class="p">],</span>
                                        <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;GnBu&#39;</span><span class="p">,</span>
                                        <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ea58a5a1aff6fc81bcfefe30c004c124aac674e3e74bae63fea65f6b9246344f.png" src="../_images/ea58a5a1aff6fc81bcfefe30c004c124aac674e3e74bae63fea65f6b9246344f.png" />
</div>
</div>
</section>
</section>
<section id="regularization-in-logistic-regression">
<h2><span class="section-number">2.5. </span>Regularization in Logistic Regression<a class="headerlink" href="#regularization-in-logistic-regression" title="Link to this heading">#</a></h2>
<p>Take a look at the documentation for <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">LogisticRegression</a>.</p>
<p>The four hyper-parameters you will likely use:</p>
<ul class="simple">
<li><p><strong>penalty</strong></p>
<ul>
<li><p>‘l1’ - use Lasso</p></li>
<li><p>‘l2’ - use Ridge (Default)</p></li>
<li><p>‘elasticnet’ - use ElasticNet</p></li>
<li><p>None - use unregularized linear regression</p></li>
</ul>
</li>
<li><p><strong>C</strong> - is the regularization parameter BUT C = 1/alpha. Small C is high regularization; large C is low regularization. Annoying.</p></li>
<li><p><strong>l1_ratio</strong> - if using ‘elasticnet’ penalty, this hyper-parameter balances the amount of L1 (Lasso) and L2 (Ridge) penalties.</p>
<ul>
<li><p>closer to 0, more Ridge</p></li>
<li><p>closer to 1, more Lasso</p></li>
</ul>
</li>
<li><p><strong>max_iter</strong> - sometimes, fitting the model won’t converge. Try increasing the value of max_iters (default is 100) and see if that fixes the problem.</p></li>
<li><p><strong>solver</strong> - different regularizations may require different solvers (how the optimal parameters are found). Let’s look at the documentation.</p></li>
</ul>
<section id="improving-our-model">
<h3><span class="section-number">2.5.1. </span>Improving our model<a class="headerlink" href="#improving-our-model" title="Link to this heading">#</a></h3>
<p>The model we fit seems to be over-fitting the data. How do I know this from the confusion matrix?</p>
<p>Let’s use some regularization to see if we can improve the fit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegressionCV</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="c1"># Train a logistic regression model</span>
<span class="n">model_LogReg_Ridge</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">penalty</span> <span class="o">=</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">Cs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">model_LogReg_Ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Make predictions</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">model_LogReg_Ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model_LogReg_Ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">y_pred_prob</span> <span class="o">=</span> <span class="n">model_LogReg_Ridge</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">,</span> 
                                        <span class="c1"># normalize = &#39;true&#39;,</span>
                                        <span class="n">display_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Benign&#39;</span><span class="p">,</span> <span class="s1">&#39;Malignant&#39;</span><span class="p">],</span>
                                        <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;GnBu&#39;</span><span class="p">,</span>
                                        <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> 
                                        <span class="c1"># normalize = &#39;true&#39;,</span>
                                        <span class="n">display_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Benign&#39;</span><span class="p">,</span> <span class="s1">&#39;Malignant&#39;</span><span class="p">],</span>
                                        <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;GnBu&#39;</span><span class="p">,</span>
                                        <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/feb96d9bcdab9ae234ea661e12a11691551e1a68a73603d937a8fd42f2d456c6.png" src="../_images/feb96d9bcdab9ae234ea661e12a11691551e1a68a73603d937a8fd42f2d456c6.png" />
</div>
</div>
</section>
<section id="id1">
<h3><span class="section-number">2.5.2. </span>Assessing the model<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>What were our most significant features?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_LogReg_Ridge</span><span class="o">.</span><span class="vm">__dict__</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;Cs&#39;: array([1.00000000e-02, 3.16227766e-02, 1.00000000e-01, 3.16227766e-01,
        1.00000000e+00, 3.16227766e+00, 1.00000000e+01, 3.16227766e+01,
        1.00000000e+02]),
 &#39;fit_intercept&#39;: True,
 &#39;cv&#39;: 5,
 &#39;dual&#39;: False,
 &#39;penalty&#39;: &#39;l2&#39;,
 &#39;scoring&#39;: None,
 &#39;tol&#39;: 0.0001,
 &#39;max_iter&#39;: 10000,
 &#39;class_weight&#39;: None,
 &#39;n_jobs&#39;: None,
 &#39;verbose&#39;: 0,
 &#39;solver&#39;: &#39;lbfgs&#39;,
 &#39;refit&#39;: True,
 &#39;intercept_scaling&#39;: 1.0,
 &#39;multi_class&#39;: &#39;deprecated&#39;,
 &#39;random_state&#39;: None,
 &#39;l1_ratios&#39;: None,
 &#39;n_features_in_&#39;: 30,
 &#39;classes_&#39;: array([0, 1]),
 &#39;Cs_&#39;: array([1.00000000e-02, 3.16227766e-02, 1.00000000e-01, 3.16227766e-01,
        1.00000000e+00, 3.16227766e+00, 1.00000000e+01, 3.16227766e+01,
        1.00000000e+02]),
 &#39;n_iter_&#39;: array([[[10,  7,  8, 12, 12, 16, 21, 23, 29],
         [ 9,  7,  8,  9, 10, 14, 14, 20, 17],
         [10,  7,  8, 10, 11, 16, 22, 26, 26],
         [10,  6,  7,  9, 11, 13, 21, 30, 26],
         [ 9,  8,  8, 12, 11, 15, 20, 15, 11]]], dtype=int32),
 &#39;scores_&#39;: {np.int64(1): array([[0.93406593, 0.97802198, 0.98901099, 0.98901099, 0.97802198,
          0.98901099, 0.98901099, 0.96703297, 0.93406593],
         [0.94505495, 0.96703297, 0.96703297, 0.96703297, 0.96703297,
          0.97802198, 0.96703297, 0.95604396, 0.95604396],
         [0.97802198, 0.98901099, 0.98901099, 1.        , 1.        ,
          1.        , 1.        , 1.        , 1.        ],
         [0.93406593, 0.95604396, 0.96703297, 0.97802198, 0.97802198,
          0.97802198, 0.97802198, 0.97802198, 0.97802198],
         [0.93406593, 0.94505495, 0.94505495, 0.93406593, 0.94505495,
          0.94505495, 0.94505495, 0.94505495, 0.94505495]])},
 &#39;coefs_paths_&#39;: {np.int64(1): array([[[ 0.18877931,  0.15354924,  0.18835075, ...,  0.15799421,
            0.05308207, -0.62707392],
          [ 0.26001545,  0.25317046,  0.25722958, ...,  0.26765068,
            0.06680208, -0.62149993],
          [ 0.32315174,  0.36240604,  0.31657734, ...,  0.45050076,
            0.07887859, -0.58505505],
          ...,
          [-0.19992366, -0.18313838, -0.24642842, ...,  2.79406576,
           -0.05705654,  0.22982167],
          [-0.72115368, -0.18133544, -0.8247711 , ...,  4.61597812,
           -0.33770871,  0.73177235],
          [-1.27061238,  0.50945972, -1.6081652 , ...,  7.68106288,
           -1.3848245 ,  0.88623181]],
  
         [[ 0.19407935,  0.1610312 ,  0.19282929, ...,  0.15803426,
            0.06208549, -0.71466605],
          [ 0.2782481 ,  0.26927561,  0.27376116, ...,  0.27343663,
            0.07898245, -0.74263137],
          [ 0.37187738,  0.38911002,  0.36187733, ...,  0.45587393,
            0.09207409, -0.76980897],
          ...,
          [ 0.48720426, -0.0536111 ,  0.31852832, ...,  2.67600778,
           -0.53317192, -0.68615334],
          [ 0.39188048,  0.03247218,  0.0542682 , ...,  4.11402491,
           -1.36680146, -0.3901461 ],
          [ 0.22874718,  0.44243786, -0.29121275, ...,  6.33994447,
           -2.42184226,  0.22317786]],
  
         [[ 0.18850543,  0.17367384,  0.1880179 , ...,  0.15486926,
            0.07403958, -0.59769658],
          [ 0.2711116 ,  0.29088627,  0.26713907, ...,  0.25437626,
            0.10366637, -0.59128212],
          [ 0.35563314,  0.41306985,  0.34485634, ...,  0.41666843,
            0.14372282, -0.58508927],
          ...,
          [ 0.16359844,  0.09733587, -0.07076539, ...,  2.52569141,
           -0.01463229,  0.23649025],
          [-0.282397  ,  0.29898835, -0.80273291, ...,  3.84916428,
           -0.4422473 ,  0.94181455],
          [-1.02417092,  0.93962937, -2.05384819, ...,  5.80342855,
           -1.18953451,  1.68586285]],
  
         [[ 0.19997914,  0.15811623,  0.19773728, ...,  0.16137979,
            0.06280437, -0.65213172],
          [ 0.28459406,  0.26940186,  0.27864513, ...,  0.26870448,
            0.08220969, -0.66336185],
          [ 0.36637957,  0.4077656 ,  0.35470213, ...,  0.42896016,
            0.097046  , -0.66788239],
          ...,
          [-0.24784738,  0.55084161, -0.40231166, ...,  1.80653513,
            0.01311299,  0.18548086],
          [-0.99713236,  0.62963699, -1.34442754, ...,  2.47198482,
           -0.09830574,  0.79818549],
          [-2.25795274,  1.15047984, -2.98278922, ...,  3.56491544,
           -0.40545261,  1.60598903]],
  
         [[ 0.19100602,  0.1763199 ,  0.18967846, ...,  0.15504789,
            0.05368948, -0.67868101],
          [ 0.2711364 ,  0.29533977,  0.26551771, ...,  0.25671223,
            0.07234754, -0.68779421],
          [ 0.35676133,  0.41859913,  0.34305118, ...,  0.42267667,
            0.1034524 , -0.67676617],
          ...,
          [ 0.42997228, -0.08864118,  0.41415401, ...,  2.60677422,
            1.39493816,  0.55349446],
          [ 0.48506192, -0.37839758,  0.51076076, ...,  3.80606774,
            2.300287  ,  1.22929661],
          [ 0.7696429 , -0.52645044,  0.82005258, ...,  5.46332712,
            3.50667034,  1.95913911]]], shape=(5, 9, 31))},
 &#39;C_&#39;: array([3.16227766]),
 &#39;l1_ratio_&#39;: array([None], dtype=object),
 &#39;coef_&#39;: array([[ 0.30024566,  0.17240886,  0.2191313 ,  0.38105667, -0.02093164,
         -1.20860703,  1.10774301,  1.89822535, -0.50315616,  0.27157447,
          2.04744451, -0.37269222,  0.57003749,  1.4691531 ,  0.52954499,
         -0.68159526, -0.57761771,  0.52984054, -0.77511646, -0.90946073,
          1.20043014,  1.96459618,  0.51709265,  1.21674533,  0.43159841,
         -0.1202286 ,  1.45955511,  0.91213833,  1.78008332,  0.12361707]]),
 &#39;intercept_&#39;: array([-0.1816065]),
 &#39;l1_ratios_&#39;: array([None], dtype=object)}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coefs</span> <span class="o">=</span> <span class="n">model_LogReg_Ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>

<span class="n">feature_weights_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;features&#39;</span><span class="p">:</span><span class="n">features</span><span class="p">,</span> <span class="s1">&#39;weights&#39;</span><span class="p">:</span><span class="n">coefs</span><span class="p">,</span> <span class="s1">&#39;abs weights&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coefs</span><span class="p">)})</span>
<span class="n">feature_weights_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s1">&#39;abs weights&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>features</th>
      <th>weights</th>
      <th>abs weights</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10</th>
      <td>radius error</td>
      <td>2.047445</td>
      <td>2.047445</td>
    </tr>
    <tr>
      <th>21</th>
      <td>worst texture</td>
      <td>1.964596</td>
      <td>1.964596</td>
    </tr>
    <tr>
      <th>7</th>
      <td>mean concave points</td>
      <td>1.898225</td>
      <td>1.898225</td>
    </tr>
    <tr>
      <th>28</th>
      <td>worst symmetry</td>
      <td>1.780083</td>
      <td>1.780083</td>
    </tr>
    <tr>
      <th>13</th>
      <td>area error</td>
      <td>1.469153</td>
      <td>1.469153</td>
    </tr>
    <tr>
      <th>26</th>
      <td>worst concavity</td>
      <td>1.459555</td>
      <td>1.459555</td>
    </tr>
    <tr>
      <th>23</th>
      <td>worst area</td>
      <td>1.216745</td>
      <td>1.216745</td>
    </tr>
    <tr>
      <th>5</th>
      <td>mean compactness</td>
      <td>-1.208607</td>
      <td>1.208607</td>
    </tr>
    <tr>
      <th>20</th>
      <td>worst radius</td>
      <td>1.200430</td>
      <td>1.200430</td>
    </tr>
    <tr>
      <th>6</th>
      <td>mean concavity</td>
      <td>1.107743</td>
      <td>1.107743</td>
    </tr>
    <tr>
      <th>27</th>
      <td>worst concave points</td>
      <td>0.912138</td>
      <td>0.912138</td>
    </tr>
    <tr>
      <th>19</th>
      <td>fractal dimension error</td>
      <td>-0.909461</td>
      <td>0.909461</td>
    </tr>
    <tr>
      <th>18</th>
      <td>symmetry error</td>
      <td>-0.775116</td>
      <td>0.775116</td>
    </tr>
    <tr>
      <th>15</th>
      <td>compactness error</td>
      <td>-0.681595</td>
      <td>0.681595</td>
    </tr>
    <tr>
      <th>16</th>
      <td>concavity error</td>
      <td>-0.577618</td>
      <td>0.577618</td>
    </tr>
    <tr>
      <th>12</th>
      <td>perimeter error</td>
      <td>0.570037</td>
      <td>0.570037</td>
    </tr>
    <tr>
      <th>17</th>
      <td>concave points error</td>
      <td>0.529841</td>
      <td>0.529841</td>
    </tr>
    <tr>
      <th>14</th>
      <td>smoothness error</td>
      <td>0.529545</td>
      <td>0.529545</td>
    </tr>
    <tr>
      <th>22</th>
      <td>worst perimeter</td>
      <td>0.517093</td>
      <td>0.517093</td>
    </tr>
    <tr>
      <th>8</th>
      <td>mean symmetry</td>
      <td>-0.503156</td>
      <td>0.503156</td>
    </tr>
    <tr>
      <th>24</th>
      <td>worst smoothness</td>
      <td>0.431598</td>
      <td>0.431598</td>
    </tr>
    <tr>
      <th>3</th>
      <td>mean area</td>
      <td>0.381057</td>
      <td>0.381057</td>
    </tr>
    <tr>
      <th>11</th>
      <td>texture error</td>
      <td>-0.372692</td>
      <td>0.372692</td>
    </tr>
    <tr>
      <th>0</th>
      <td>mean radius</td>
      <td>0.300246</td>
      <td>0.300246</td>
    </tr>
    <tr>
      <th>9</th>
      <td>mean fractal dimension</td>
      <td>0.271574</td>
      <td>0.271574</td>
    </tr>
    <tr>
      <th>2</th>
      <td>mean perimeter</td>
      <td>0.219131</td>
      <td>0.219131</td>
    </tr>
    <tr>
      <th>1</th>
      <td>mean texture</td>
      <td>0.172409</td>
      <td>0.172409</td>
    </tr>
    <tr>
      <th>29</th>
      <td>worst fractal dimension</td>
      <td>0.123617</td>
      <td>0.123617</td>
    </tr>
    <tr>
      <th>25</th>
      <td>worst compactness</td>
      <td>-0.120229</td>
      <td>0.120229</td>
    </tr>
    <tr>
      <th>4</th>
      <td>mean smoothness</td>
      <td>-0.020932</td>
      <td>0.020932</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>
<section id="another-example-classifying-wines">
<h2><span class="section-number">2.6. </span>Another Example: Classifying Wines<a class="headerlink" href="#another-example-classifying-wines" title="Link to this heading">#</a></h2>
<p>In this classification problem, we are given chemical properties of wine as well as a target value corresponding to the vineyard the wine came from. Can we identify which vineyard a wine came from by analyzing the chemical content of the wine itself?</p>
<p>There are three categories of wine in this classification (0,1,2). Below, I’ve set up the problem so that you can fit a binary logistic regression or a multi-class just by toggling the comments on a few lines of code in the next cell. Everything else can stay the same; the LogisticRegression model will handle both cases.</p>
<p>For multi-class classification, we can leave the target variable as it is in the original data set.</p>
<p>For binary classification, we will relabel the target so that:</p>
<ul class="simple">
<li><p>1 = <em>the wine is from vineyard 1</em></p></li>
<li><p>0 = <em>the wine is from either vineyard 0 or 2 (not 1)</em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_wine</span>

<span class="n">wine_df</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_wine</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Multi-class (3) problem</span>
<span class="n">wine_df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
<span class="n">vineyard_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Vineyard 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Vineyard 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Vineyard 2&#39;</span><span class="p">]</span>

<span class="c1"># # Binary Classification problem</span>
<span class="c1"># vineyard_labels = [&#39;Not Vineyard 1&#39;, &#39;Vineyard 1&#39;]</span>
<span class="c1"># wine_df[&#39;y&#39;] = 1 * (y==1)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">wine_df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>



<span class="n">wine_df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0 1 2]
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>malic_acid</th>
      <th>ash</th>
      <th>alcalinity_of_ash</th>
      <th>magnesium</th>
      <th>total_phenols</th>
      <th>flavanoids</th>
      <th>nonflavanoid_phenols</th>
      <th>proanthocyanins</th>
      <th>color_intensity</th>
      <th>hue</th>
      <th>od280/od315_of_diluted_wines</th>
      <th>proline</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>71</th>
      <td>13.86</td>
      <td>1.51</td>
      <td>2.67</td>
      <td>25.0</td>
      <td>86.0</td>
      <td>2.95</td>
      <td>2.86</td>
      <td>0.21</td>
      <td>1.87</td>
      <td>3.38</td>
      <td>1.36</td>
      <td>3.16</td>
      <td>410.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>29</th>
      <td>14.02</td>
      <td>1.68</td>
      <td>2.21</td>
      <td>16.0</td>
      <td>96.0</td>
      <td>2.65</td>
      <td>2.33</td>
      <td>0.26</td>
      <td>1.98</td>
      <td>4.70</td>
      <td>1.04</td>
      <td>3.59</td>
      <td>1035.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>91</th>
      <td>12.00</td>
      <td>1.51</td>
      <td>2.42</td>
      <td>22.0</td>
      <td>86.0</td>
      <td>1.45</td>
      <td>1.25</td>
      <td>0.50</td>
      <td>1.63</td>
      <td>3.60</td>
      <td>1.05</td>
      <td>2.65</td>
      <td>450.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>79</th>
      <td>12.70</td>
      <td>3.87</td>
      <td>2.40</td>
      <td>23.0</td>
      <td>101.0</td>
      <td>2.83</td>
      <td>2.55</td>
      <td>0.43</td>
      <td>1.95</td>
      <td>2.57</td>
      <td>1.19</td>
      <td>3.13</td>
      <td>463.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>66</th>
      <td>13.11</td>
      <td>1.01</td>
      <td>1.70</td>
      <td>15.0</td>
      <td>78.0</td>
      <td>2.98</td>
      <td>3.18</td>
      <td>0.26</td>
      <td>2.28</td>
      <td>5.30</td>
      <td>1.12</td>
      <td>3.18</td>
      <td>502.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>15</th>
      <td>13.63</td>
      <td>1.81</td>
      <td>2.70</td>
      <td>17.2</td>
      <td>112.0</td>
      <td>2.85</td>
      <td>2.91</td>
      <td>0.30</td>
      <td>1.46</td>
      <td>7.30</td>
      <td>1.28</td>
      <td>2.88</td>
      <td>1310.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>67</th>
      <td>12.37</td>
      <td>1.17</td>
      <td>1.92</td>
      <td>19.6</td>
      <td>78.0</td>
      <td>2.11</td>
      <td>2.00</td>
      <td>0.27</td>
      <td>1.04</td>
      <td>4.68</td>
      <td>1.12</td>
      <td>3.48</td>
      <td>510.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>177</th>
      <td>14.13</td>
      <td>4.10</td>
      <td>2.74</td>
      <td>24.5</td>
      <td>96.0</td>
      <td>2.05</td>
      <td>0.76</td>
      <td>0.56</td>
      <td>1.35</td>
      <td>9.20</td>
      <td>0.61</td>
      <td>1.60</td>
      <td>560.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>164</th>
      <td>13.78</td>
      <td>2.76</td>
      <td>2.30</td>
      <td>22.0</td>
      <td>90.0</td>
      <td>1.35</td>
      <td>0.68</td>
      <td>0.41</td>
      <td>1.03</td>
      <td>9.58</td>
      <td>0.70</td>
      <td>1.68</td>
      <td>615.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>61</th>
      <td>12.64</td>
      <td>1.36</td>
      <td>2.02</td>
      <td>16.8</td>
      <td>100.0</td>
      <td>2.02</td>
      <td>1.41</td>
      <td>0.53</td>
      <td>0.62</td>
      <td>5.75</td>
      <td>0.98</td>
      <td>1.59</td>
      <td>450.0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split the data into features and target</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine_df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">])</span>

<span class="n">X</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>malic_acid</th>
      <th>ash</th>
      <th>alcalinity_of_ash</th>
      <th>magnesium</th>
      <th>total_phenols</th>
      <th>flavanoids</th>
      <th>nonflavanoid_phenols</th>
      <th>proanthocyanins</th>
      <th>color_intensity</th>
      <th>hue</th>
      <th>od280/od315_of_diluted_wines</th>
      <th>proline</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>14.23</td>
      <td>1.71</td>
      <td>2.43</td>
      <td>15.6</td>
      <td>127.0</td>
      <td>2.80</td>
      <td>3.06</td>
      <td>0.28</td>
      <td>2.29</td>
      <td>5.64</td>
      <td>1.04</td>
      <td>3.92</td>
      <td>1065.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>13.20</td>
      <td>1.78</td>
      <td>2.14</td>
      <td>11.2</td>
      <td>100.0</td>
      <td>2.65</td>
      <td>2.76</td>
      <td>0.26</td>
      <td>1.28</td>
      <td>4.38</td>
      <td>1.05</td>
      <td>3.40</td>
      <td>1050.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>13.16</td>
      <td>2.36</td>
      <td>2.67</td>
      <td>18.6</td>
      <td>101.0</td>
      <td>2.80</td>
      <td>3.24</td>
      <td>0.30</td>
      <td>2.81</td>
      <td>5.68</td>
      <td>1.03</td>
      <td>3.17</td>
      <td>1185.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>14.37</td>
      <td>1.95</td>
      <td>2.50</td>
      <td>16.8</td>
      <td>113.0</td>
      <td>3.85</td>
      <td>3.49</td>
      <td>0.24</td>
      <td>2.18</td>
      <td>7.80</td>
      <td>0.86</td>
      <td>3.45</td>
      <td>1480.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>13.24</td>
      <td>2.59</td>
      <td>2.87</td>
      <td>21.0</td>
      <td>118.0</td>
      <td>2.80</td>
      <td>2.69</td>
      <td>0.39</td>
      <td>1.82</td>
      <td>4.32</td>
      <td>1.04</td>
      <td>2.93</td>
      <td>735.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>173</th>
      <td>13.71</td>
      <td>5.65</td>
      <td>2.45</td>
      <td>20.5</td>
      <td>95.0</td>
      <td>1.68</td>
      <td>0.61</td>
      <td>0.52</td>
      <td>1.06</td>
      <td>7.70</td>
      <td>0.64</td>
      <td>1.74</td>
      <td>740.0</td>
    </tr>
    <tr>
      <th>174</th>
      <td>13.40</td>
      <td>3.91</td>
      <td>2.48</td>
      <td>23.0</td>
      <td>102.0</td>
      <td>1.80</td>
      <td>0.75</td>
      <td>0.43</td>
      <td>1.41</td>
      <td>7.30</td>
      <td>0.70</td>
      <td>1.56</td>
      <td>750.0</td>
    </tr>
    <tr>
      <th>175</th>
      <td>13.27</td>
      <td>4.28</td>
      <td>2.26</td>
      <td>20.0</td>
      <td>120.0</td>
      <td>1.59</td>
      <td>0.69</td>
      <td>0.43</td>
      <td>1.35</td>
      <td>10.20</td>
      <td>0.59</td>
      <td>1.56</td>
      <td>835.0</td>
    </tr>
    <tr>
      <th>176</th>
      <td>13.17</td>
      <td>2.59</td>
      <td>2.37</td>
      <td>20.0</td>
      <td>120.0</td>
      <td>1.65</td>
      <td>0.68</td>
      <td>0.53</td>
      <td>1.46</td>
      <td>9.30</td>
      <td>0.60</td>
      <td>1.62</td>
      <td>840.0</td>
    </tr>
    <tr>
      <th>177</th>
      <td>14.13</td>
      <td>4.10</td>
      <td>2.74</td>
      <td>24.5</td>
      <td>96.0</td>
      <td>2.05</td>
      <td>0.76</td>
      <td>0.56</td>
      <td>1.35</td>
      <td>9.20</td>
      <td>0.61</td>
      <td>1.60</td>
      <td>560.0</td>
    </tr>
  </tbody>
</table>
<p>178 rows × 13 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Scale the data</span>
<span class="n">ss</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># I&#39;m choosing to use logistic regression with Lasso (L1) penalty</span>
<span class="c1"># One hyper-parameter is solver and not all solvers work for all parameters</span>
<span class="n">logreg_lasso</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">penalty</span> <span class="o">=</span> <span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="n">Cs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">13</span><span class="p">),</span> <span class="n">solver</span> <span class="o">=</span> <span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">logreg_lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>


<span class="c1"># Make predictions</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">logreg_lasso</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">logreg_lasso</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>

<span class="n">y_proba</span> <span class="o">=</span> <span class="n">logreg_lasso</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">,</span> 
                                        <span class="c1"># normalize = &#39;true&#39;,</span>
                                        <span class="n">display_labels</span> <span class="o">=</span> <span class="n">vineyard_labels</span><span class="p">,</span>
                                        <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;GnBu&#39;</span><span class="p">,</span>
                                        <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> 
                                        <span class="c1"># normalize = &#39;true&#39;,</span>
                                        <span class="n">display_labels</span> <span class="o">=</span> <span class="n">vineyard_labels</span><span class="p">,</span>
                                        <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;GnBu&#39;</span><span class="p">,</span>
                                        <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/64e1cd407b04679478086cecb1859b91cb37a272e9116bf00e15d276aa6b0fb2.png" src="../_images/64e1cd407b04679478086cecb1859b91cb37a272e9116bf00e15d276aa6b0fb2.png" />
</div>
</div>
<p><strong>What were the most important features?</strong></p>
<ul class="simple">
<li><p>Get the feature names from the columns of X</p></li>
<li><p>Get the coefficients from the model and calculate their absolute values</p></li>
<li><p>Create a dataframe with columns: features, weights, abs weights</p></li>
<li><p>Sort by abs weight</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Follow the instructions above</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>

<span class="c1"># When we perform multiple logistic regressions, we get multiple sets of coefficients</span>
<span class="c1"># The algorithm fits several binary logistic regressions to solve the multi-class problem</span>
<span class="n">coefs</span> <span class="o">=</span> <span class="n">logreg_lasso</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

<span class="n">features_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;features&#39;</span><span class="p">:</span> <span class="n">features</span><span class="p">,</span> <span class="s1">&#39;coef&#39;</span><span class="p">:</span><span class="n">coefs</span><span class="p">,</span> <span class="s1">&#39;abs coef&#39;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coefs</span><span class="p">)})</span>
<span class="n">features_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s1">&#39;abs coef&#39;</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>features</th>
      <th>coef</th>
      <th>abs coef</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>flavanoids</td>
      <td>-4.485358</td>
      <td>4.485358</td>
    </tr>
    <tr>
      <th>9</th>
      <td>color_intensity</td>
      <td>2.195638</td>
      <td>2.195638</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ash</td>
      <td>0.914783</td>
      <td>0.914783</td>
    </tr>
    <tr>
      <th>10</th>
      <td>hue</td>
      <td>-0.672959</td>
      <td>0.672959</td>
    </tr>
    <tr>
      <th>7</th>
      <td>nonflavanoid_phenols</td>
      <td>-0.571479</td>
      <td>0.571479</td>
    </tr>
    <tr>
      <th>1</th>
      <td>malic_acid</td>
      <td>0.455491</td>
      <td>0.455491</td>
    </tr>
    <tr>
      <th>11</th>
      <td>od280/od315_of_diluted_wines</td>
      <td>-0.092544</td>
      <td>0.092544</td>
    </tr>
    <tr>
      <th>0</th>
      <td>alcohol</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>alcalinity_of_ash</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>magnesium</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>total_phenols</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>8</th>
      <td>proanthocyanins</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>12</th>
      <td>proline</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_proba</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[9.97044576e-01, 9.57737319e-09, 2.95541450e-03],
       [9.17236576e-06, 1.94012081e-02, 9.80589620e-01],
       [1.03906676e-06, 9.72579941e-07, 9.99997988e-01],
       [2.32391569e-05, 5.18195562e-01, 4.81781199e-01],
       [9.99221796e-01, 1.38898356e-04, 6.39305349e-04],
       [3.40815629e-04, 1.98792389e-07, 9.99658986e-01],
       [1.68325005e-03, 2.04776169e-07, 9.98316545e-01],
       [2.07327421e-04, 9.98141173e-01, 1.65149942e-03],
       [2.08529639e-05, 2.47837114e-01, 7.52142033e-01],
       [4.57257900e-07, 9.99851664e-01, 1.47879152e-04],
       [3.64571984e-05, 9.98450820e-01, 1.51272242e-03],
       [3.04025313e-03, 9.99708362e-10, 9.96959746e-01],
       [9.99790673e-01, 1.27974707e-07, 2.09199353e-04],
       [6.61183160e-03, 9.93088019e-01, 3.00149022e-04],
       [3.49261222e-05, 9.62107699e-01, 3.78573745e-02],
       [9.99547937e-01, 8.68880032e-07, 4.51194067e-04],
       [3.07358237e-03, 9.96114025e-01, 8.12392202e-04],
       [9.93489975e-01, 2.99365127e-03, 3.51637383e-03],
       [9.97889001e-01, 3.66601824e-06, 2.10733333e-03],
       [9.99694718e-01, 2.25197027e-05, 2.82762160e-04],
       [9.78333644e-01, 2.14018075e-02, 2.64548884e-04],
       [3.34345861e-03, 9.95579000e-01, 1.07754089e-03],
       [9.14843055e-04, 2.59025676e-06, 9.99082567e-01],
       [5.41164005e-04, 1.20024064e-06, 9.99457636e-01],
       [6.71557979e-06, 8.43556428e-06, 9.99984849e-01],
       [1.75840533e-04, 1.45820063e-05, 9.99809577e-01],
       [8.65640512e-05, 1.62532752e-05, 9.99897183e-01],
       [1.26218060e-06, 9.80984845e-01, 1.90138929e-02],
       [9.99603087e-01, 3.88864641e-04, 8.04836320e-06],
       [2.59411447e-05, 9.98827795e-01, 1.14626346e-03],
       [6.72821999e-03, 9.81212736e-01, 1.20590441e-02],
       [9.09297611e-06, 9.96234884e-01, 3.75602308e-03],
       [1.71460590e-03, 9.98281964e-01, 3.43007892e-06],
       [1.43038698e-05, 8.24435803e-01, 1.75549893e-01],
       [1.08931470e-04, 1.73767473e-06, 9.99889331e-01],
       [1.85295801e-04, 9.96680874e-01, 3.13383062e-03],
       [2.65284871e-05, 2.89119029e-03, 9.97082281e-01],
       [2.30393770e-07, 9.97869164e-01, 2.13060535e-03],
       [4.49251602e-05, 9.93546278e-01, 6.40879650e-03],
       [5.88574589e-01, 4.11353823e-01, 7.15879365e-05],
       [2.03122770e-04, 4.65954809e-08, 9.99796831e-01],
       [1.26129380e-07, 6.62007699e-04, 9.99337866e-01],
       [2.34225821e-02, 3.11762572e-04, 9.76265655e-01],
       [7.95939834e-01, 2.03950641e-01, 1.09525105e-04],
       [9.60134745e-02, 9.03600916e-01, 3.85609471e-04]])
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./02_Classification"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="01_classification_intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1. </span>Classification</p>
      </div>
    </a>
    <a class="right-next"
       href="03_trees_encoding.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Trees and Ensemble methods</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-simple-logistic-regression-as-a-classifier">2.1. Example: Simple Logistic Regression as a Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-logistic-function">2.2. The Logistic Function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-and-linear-regression">2.3. Logistic and Linear Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cost-function">2.3.1. Cost Function</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#back-to-the-example">2.4. Back to the Example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#assessing-the-model">2.4.1. Assessing the model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-in-logistic-regression">2.5. Regularization in Logistic Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#improving-our-model">2.5.1. Improving our model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">2.5.2. Assessing the model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#another-example-classifying-wines">2.6. Another Example: Classifying Wines</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Eatai Roth, Gettysburg College
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>