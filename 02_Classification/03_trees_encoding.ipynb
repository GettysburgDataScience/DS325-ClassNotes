{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees and Ensemble methods\n",
    "\n",
    "But first..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with discrete data: Ordinal and Categorical\n",
    "\n",
    "Discrete data come in two flavors, *ordinal* and *categorical*:\n",
    "\n",
    " - *ordinal data* - can be ordered\n",
    "    - 'low', 'medium', 'high'\n",
    "    - 'F', 'D-', 'D', 'D+', 'C-', 'C', 'C+', ..., 'A', 'A+'\n",
    "    - '1 br', '2 br', '3 br', ...\n",
    "\n",
    "- *categorical data* - are not ordered\n",
    "    - 'cat', 'dog', 'parrot', 'hamster'\n",
    "    - 'faculty', 'staff', 'student'\n",
    "    - 'never licensed', 'valid permit', 'valid license', 'suspended/expired license'\n",
    "\n",
    "Using ```sklearn```, we need to convert these categories into numerical values. There are several transforms available, and which we choose depends on the data.\n",
    "\n",
    " - [OrdinalEncoder(categories = list_of_lists_of_categories)](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) - **for ordinal data**. We tell the ordinal encoder the order of the string data using a list (see example below). OrdinalEncoder can be applied to multiple columns at a time. (e.g. ['low','med','high] ---> [0, 1, 2])\n",
    "    - Ordinal encoding will replace ordered variables into numbers (0,1,2,...) in a single column.\n",
    " - [OneHotEncoder()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) -  **for categorical data**. one-hot encoding of mutually exclusive categorical variables.\n",
    "    - One-Hot encoding creates a new feature for each possible value. Each row will have a 1 in a single column and 0 in the others, hence *one hot*.\n",
    " - [LabelEncoder()] (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)- **for categorical data**. Label encoding is intended to be used only on the label/target y, hence can only be applied to one column at a time. However, we will use Label encoding to transform any binary string data (e.g. Sex = ['M','F']--->[0,1]) instead of one-hot encoding\n",
    "\n",
    "We can apply different transforms to different columns of our data using [ColumnTransformer()] (https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html).\n",
    "\n",
    "Let's look at an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_name</th>\n",
       "      <th>student_grade</th>\n",
       "      <th>student_major</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alma</td>\n",
       "      <td>A</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barak</td>\n",
       "      <td>A+</td>\n",
       "      <td>Econ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Connell</td>\n",
       "      <td>B+</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Devon</td>\n",
       "      <td>B</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eatai</td>\n",
       "      <td>C+</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Felicia</td>\n",
       "      <td>A</td>\n",
       "      <td>Econ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_name student_grade student_major\n",
       "0         Alma             A      Business\n",
       "1        Barak            A+          Econ\n",
       "2      Connell            B+      Business\n",
       "3        Devon             B            CS\n",
       "4        Eatai            C+            CS\n",
       "5      Felicia             A          Econ"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "grade_roster = dict(\n",
    "    student_name = ['Alma', 'Barak', 'Connell', 'Devon', 'Eatai', 'Felicia'],\n",
    "    student_grade = ['A', 'A+', 'B+', 'B', 'C+', 'A'],\n",
    "    student_major = ['Business', 'Econ', 'Business', 'CS', 'CS', 'Econ']\n",
    ")\n",
    "\n",
    "grade_roster_df = pd.DataFrame(grade_roster)\n",
    "grade_roster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.0, 1.0, 0.0, 0.0, 'Alma'],\n",
       "       [12.0, 0.0, 0.0, 1.0, 'Barak'],\n",
       "       [9.0, 1.0, 0.0, 0.0, 'Connell'],\n",
       "       [8.0, 0.0, 1.0, 0.0, 'Devon'],\n",
       "       [6.0, 0.0, 1.0, 0.0, 'Eatai'],\n",
       "       [11.0, 0.0, 0.0, 1.0, 'Felicia']], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "grades = ['F', 'D-', 'D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A', 'A+']\n",
    "ord_features = ['student_grade']\n",
    "ordEnc = OrdinalEncoder(categories = [grades])\n",
    "\n",
    "cat_features = ['student_major']\n",
    "oneHotEnc = OneHotEncoder()\n",
    "\n",
    "\n",
    "coltrans = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ord\", ordEnc, ord_features),\n",
    "        (\"onehot\", oneHotEnc, cat_features)\n",
    "        ],\n",
    "    remainder = 'passthrough',\n",
    "    verbose_feature_names_out=False)\n",
    "\n",
    "X_trans = coltrans.fit_transform(grade_roster_df)\n",
    "X_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['student_grade', 'student_major_Business', 'student_major_CS',\n",
       "       'student_major_Econ', 'student_name'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_names = coltrans.get_feature_names_out()\n",
    "new_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_grade</th>\n",
       "      <th>student_major_Business</th>\n",
       "      <th>student_major_CS</th>\n",
       "      <th>student_major_Econ</th>\n",
       "      <th>student_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Barak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Connell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Devon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Eatai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Felicia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_grade student_major_Business student_major_CS student_major_Econ  \\\n",
       "0          11.0                    1.0              0.0                0.0   \n",
       "1          12.0                    0.0              0.0                1.0   \n",
       "2           9.0                    1.0              0.0                0.0   \n",
       "3           8.0                    0.0              1.0                0.0   \n",
       "4           6.0                    0.0              1.0                0.0   \n",
       "5          11.0                    0.0              0.0                1.0   \n",
       "\n",
       "  student_name  \n",
       "0         Alma  \n",
       "1        Barak  \n",
       "2      Connell  \n",
       "3        Devon  \n",
       "4        Eatai  \n",
       "5      Felicia  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_roster_df2 = pd.DataFrame(X_trans, columns = new_feature_names)\n",
    "grade_roster_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision/Classification Trees\n",
    "\n",
    "Tree-based models --- Decision/Classification Trees and Regression Trees --- are a family of algorithms that approach classification and regression using a heirarchy of conditional/if-else statements (imagine a flow chart or a game of 20 questions). You might describe tree-based models as human-like in their approach to problem solving. And these models are not only intuitive and interpretable, they are some of the most ubiquitous and powerful algorithms in ML.\n",
    "\n",
    "We'll start by looking at a cartoon example of a decision tree, this one predicts whether a casual golfer is expected to shoot below or above par on a given outing.\n",
    "\n",
    "<img src=\"tree-graphic.jpg\" alt=\"https://www.mastersindatascience.org/wp-content/uploads/sites/54/2022/05/tree-graphic.jpg\" width = 600 />\n",
    "\n",
    "### Anatomy of a tree\n",
    "- *Decision node* - a binary question that divides the data set\n",
    "- *Root node* - the top decision node in the tree\n",
    "- *Leaf node* - a terminal node where the classification is made\n",
    "- *Parent/Child node* - the node before/after a split\n",
    "- *Split* - the forks off a node\n",
    "- *Branch* - all the decision and leaf nodes that spawn from a single up-stream decision\n",
    "\n",
    "While the cartoon does a good job showing the structure and flow of a decision tree, it's important to clarify an important detail about the nodes.\n",
    "\n",
    "In the example, some of the nodes are truly categorical questions:\n",
    " - \"With friends?\"\n",
    " - \"Walk or cart?\"\n",
    "\n",
    " While others are seemingly subjective. To make the subjective nodes binary, we define the question in terms of inequalities:\n",
    "  - \"Windy?\" is ambiguous. Is 2 mph winds windy? 5 mph? 20 mph? Instead we would use an inequality on the feature: wind > 5 mph\n",
    "  - \"Cold?\" is similarly ambiguous. So a node splitting on temperature would need to be formulated as an inequality: temp < 50 F\n",
    "\n",
    "\n",
    "  ### How do we choose what a good condition for a node would be?\n",
    "\n",
    "  It is preferable for tree-models to have fewer nodes; smaller models are better. And ideally, each leaf node would represent a set of samples that all belonged to the same class, that is to say, if you followed the branches down to that leaf node, your classification would be correct (and this is not always possible). \n",
    "  \n",
    "  Intuitively, what questions might you ask to classify:\n",
    "   - animals into their classes: Mammals, Birds, Reptiles, Amphibians, and Fish.\n",
    "   - beers into their types: pilsner, lager, ale, porter, stout\n",
    "   - movies into hits or flops\n",
    "   - voters into their political leanings: Liberal, Conservative, Libertarian, Populist, etc.\n",
    "\n",
    "  Towards this ideal, at each node, we would want a conditional statement that split the set in a way so that the resulting subsets are as homogeneous (mostly or all one class) as possible. This homogeneity is referred to as the \"purity\" of the node, and there are different ways of quantifying said purity: *Gini Impurity* and *Information Gain*.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Gini Impurity\n",
    "   *Gini impurity* is the likelihood of randomly misclassifying a randomly selected sample given the distribution of samples in the set; that is, if you randomly select a sample and randomly select a label, Gini impurity is the likelihood of a mismatch. A Gini impurity of zero represents a perfectly homogeneous set (all the same class).\n",
    "\n",
    "   If using Gini impurity as the criterion, the fitting algorithm will choose conditions to minimize the Gini impurity at each successive split (using a greedy algorithm).\n",
    "   \n",
    "   The Gini index for a *sub-node* is:\n",
    "   \n",
    "   $$\n",
    "   I(p) = \\sum_{i=1}^M p_i(1-p_i) \\\\\n",
    "   = 1- \\sum_{i=1}^M p_i^2\n",
    "   $$\n",
    "   \n",
    "   where:\n",
    "   \n",
    "   - $i$ is the class index\n",
    "   - $M$ is the number of classes\n",
    "   - $p_i$ is the proportion of a given class in the subset.\n",
    "\n",
    "   The Gini impurity for a split is the sum of the Gini index for each resultant node, weighted by the number of samples in each node.\n",
    "\n",
    "  $$\n",
    "  I(p) = \\frac{1}{N}\\sum_{k=1}^M n_k I_k(p)\n",
    "  $$\n",
    "   \n",
    "  where:\n",
    "   \n",
    "   - $N$ is the sample size at the parent node\n",
    "   - $n_k$ is the sample size at each sub-node\n",
    "\n",
    "   Example: Dogs, Cat, Mouse classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain\n",
    "\n",
    "*Entropy* in physics quantifies dis-order. Analagously, *entropy* in information theory quantifies uncertainty.\n",
    "\n",
    "Entropy (H) of a set is defined as:\n",
    "\n",
    "$$\n",
    "H(p) = - \\sum_{i=1}^M p_i \\log(p_i)\n",
    "$$\n",
    "\n",
    "What is the entropy if $p_i = 0$ or $p_i = 1$?\n",
    "\n",
    "When entropy is zero, there is no uncertainity; in the case of a decision tree, the subsample is perfectly homogeneous.\n",
    "\n",
    "*Information gain* is the reduction of entropy between the parent and child node.\n",
    "\n",
    "$$\n",
    "IG(p) = H_{\\text{parent}}(p) - \\sum H_{\\text{children}}(p)\n",
    "$$\n",
    "\n",
    "If using Information Gain as the criterion, the fitting algorithm will choose conditions to maximize Information Gain (reduce entropy) at each successive split (using a greedy algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Drug prescriptions\n",
    "\n",
    "For this example, we'll be looking at the drug200 data set (https://www.kaggle.com/datasets/prathamtripathi/drug-classification).\n",
    "\n",
    "The dataset summarizes the demographics and health condition of 200 patients (Age, sex, blood, pressure, cholesterol, and sodium/potassium ratio) as well as which of five drugs had best results with the patient. The goal is to build a classifier to choose which drug to prescribe to a future patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_df = pd.read_csv('https://raw.githubusercontent.com/kvinlazy/Dataset/refs/heads/master/drug200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Age          200 non-null    int64  \n",
      " 1   Sex          200 non-null    object \n",
      " 2   BP           200 non-null    object \n",
      " 3   Cholesterol  200 non-null    object \n",
      " 4   Na_to_K      200 non-null    float64\n",
      " 5   Drug         200 non-null    object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 9.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0   23   F    HIGH        HIGH   25.355  drugY\n",
       "1   47   M     LOW        HIGH   13.093  drugC\n",
       "2   47   M     LOW        HIGH   10.114  drugC\n",
       "3   28   F  NORMAL        HIGH    7.798  drugX\n",
       "4   61   F     LOW        HIGH   18.043  drugY"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(drugs_df.info())\n",
    "display(drugs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform (Encode) the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth = 4)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize = (15, 6))\n",
    "plot_tree(tree_clf,\n",
    "          feature_names = feature_names,\n",
    "          class_names = class_names,\n",
    "          filled = True, fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cfm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cfm, display_labels = y_label).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
